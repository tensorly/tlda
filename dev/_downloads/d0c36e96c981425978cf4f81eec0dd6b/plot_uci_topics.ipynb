{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Fitting TLDA on UCI-Newsgroups\n\nIn this example, we show how to run TLDA on a subset of the UCI 20 Newsgroups dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop_words = list(stopwords.words('english'))\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.datasets import fetch_20newsgroups\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\n# Import TensorLy\nimport tensorly as tl\n\n# Import functions from tensor lda method\nfrom tlda.tlda_wrapper import TLDA\n\nseed = 0\ntl.set_backend(\"numpy\")\nnp.random.seed(seed)\n\nprint(\"Loading dataset with 2 topics: Autos and Baseball\")\n# Fetch data from 20 newsgroups dataset\ncategories = ['rec.autos', 'rec.sport.baseball']\nnewsgroups_test = fetch_20newsgroups(remove=('headers', 'footers', 'quotes'),\n                                     categories=categories)\ntexts = newsgroups_test.data\n\n# Generate count vectors from documents.\nvectorizer = CountVectorizer(min_df = 0.05,\n                             max_df = 0.2,\n                             ngram_range = (1, 2),\n                             stop_words = stop_words)\nvectors = vectorizer.fit_transform(texts).toarray()\nvocab = vectorizer.get_feature_names_out()\n\nprint(\"Running tensor LDA\")\n# Initialize Tensor LDA\nk = len(categories)\ntlda = TLDA(\n      n_topic = k, alpha_0 = 0.01, n_iter_train = 2000, n_iter_test = 10,\n      learning_rate = 1e-5, pca_batch_size = 10000,\n      third_order_cumulant_batch = 10, theta=5.005, ortho_loss_criterion = 1,\n      random_seed = seed, n_eigenvec = k*5\n    )\n\n# Fit Tensor LDA\ntlda.fit(vectors)\n\nprint(\"Creating image to display fitted topics\")\n# Generate a wordcloud from the topics\n\ntopic_order = np.argsort(tlda.weights_)\n\ncloud = WordCloud(stopwords=stop_words,\n              background_color='white',\n              width=1000*k,\n              height=1000,\n              max_words=25,\n              colormap='tab10')\n\nfig, axes = plt.subplots(1, 2, figsize=(7, 7),\n                         sharey=True)\n\nfor i, ax in enumerate(axes.flatten()):\n    fig.add_subplot(ax)\n    if i < k:\n        cloud.generate_from_frequencies(dict(zip(vocab, tlda.unwhitened_factors.T[topic_order[i], :])))\n        plt.gca().imshow(cloud)\n        plt.gca().set_title('Topic ' + str(topic_order[i]), fontdict=dict(size=16))\n    plt.gca().axis('off')\n\nplt.subplots_adjust(wspace=0, hspace=0)\nplt.axis('off')\nplt.margins(x=0, y=0)\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}